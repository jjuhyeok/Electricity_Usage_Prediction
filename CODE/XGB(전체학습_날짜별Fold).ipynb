{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0HsYh0JiUKoI"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import sktime\n",
        "import tqdm as tq\n",
        "import xgboost as xgb\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import sklearn as skl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "from sktime.utils.plotting import plot_series\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def SMAPE(true, pred):\n",
        "    v = 2 * abs(pred - true) / (abs(pred) + abs(true))\n",
        "    output = np.mean(v) * 100\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_date_time</th>\n",
              "      <th>건물번호</th>\n",
              "      <th>일시</th>\n",
              "      <th>기온(C)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>습도(%)</th>\n",
              "      <th>일조(hr)</th>\n",
              "      <th>일사(MJ/m2)</th>\n",
              "      <th>전력소비량(kWh)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_20220601 00</td>\n",
              "      <td>1</td>\n",
              "      <td>20220601 00</td>\n",
              "      <td>18.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9</td>\n",
              "      <td>42.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1085.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_20220601 01</td>\n",
              "      <td>1</td>\n",
              "      <td>20220601 01</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.1</td>\n",
              "      <td>45.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1047.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_20220601 02</td>\n",
              "      <td>1</td>\n",
              "      <td>20220601 02</td>\n",
              "      <td>17.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.5</td>\n",
              "      <td>45.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>974.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_20220601 03</td>\n",
              "      <td>1</td>\n",
              "      <td>20220601 03</td>\n",
              "      <td>16.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.4</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>953.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_20220601 04</td>\n",
              "      <td>1</td>\n",
              "      <td>20220601 04</td>\n",
              "      <td>18.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.8</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>986.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203995</th>\n",
              "      <td>100_20220824 19</td>\n",
              "      <td>100</td>\n",
              "      <td>20220824 19</td>\n",
              "      <td>23.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>881.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203996</th>\n",
              "      <td>100_20220824 20</td>\n",
              "      <td>100</td>\n",
              "      <td>20220824 20</td>\n",
              "      <td>22.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.3</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>798.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203997</th>\n",
              "      <td>100_20220824 21</td>\n",
              "      <td>100</td>\n",
              "      <td>20220824 21</td>\n",
              "      <td>21.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>825.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203998</th>\n",
              "      <td>100_20220824 22</td>\n",
              "      <td>100</td>\n",
              "      <td>20220824 22</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3</td>\n",
              "      <td>94.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>640.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203999</th>\n",
              "      <td>100_20220824 23</td>\n",
              "      <td>100</td>\n",
              "      <td>20220824 23</td>\n",
              "      <td>20.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>540.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          num_date_time  건물번호           일시  기온(C)  강수량(mm)  풍속(m/s)  습도(%)  \\\n",
              "0         1_20220601 00     1  20220601 00   18.6      NaN      0.9   42.0   \n",
              "1         1_20220601 01     1  20220601 01   18.0      NaN      1.1   45.0   \n",
              "2         1_20220601 02     1  20220601 02   17.7      NaN      1.5   45.0   \n",
              "3         1_20220601 03     1  20220601 03   16.7      NaN      1.4   48.0   \n",
              "4         1_20220601 04     1  20220601 04   18.4      NaN      2.8   43.0   \n",
              "...                 ...   ...          ...    ...      ...      ...    ...   \n",
              "203995  100_20220824 19   100  20220824 19   23.1      NaN      0.9   86.0   \n",
              "203996  100_20220824 20   100  20220824 20   22.4      NaN      1.3   86.0   \n",
              "203997  100_20220824 21   100  20220824 21   21.3      NaN      1.0   92.0   \n",
              "203998  100_20220824 22   100  20220824 22   21.0      NaN      0.3   94.0   \n",
              "203999  100_20220824 23   100  20220824 23   20.7      NaN      0.1   95.0   \n",
              "\n",
              "        일조(hr)  일사(MJ/m2)  전력소비량(kWh)  \n",
              "0          NaN        NaN     1085.28  \n",
              "1          NaN        NaN     1047.36  \n",
              "2          NaN        NaN      974.88  \n",
              "3          NaN        NaN      953.76  \n",
              "4          NaN        NaN      986.40  \n",
              "...        ...        ...         ...  \n",
              "203995     0.5        NaN      881.04  \n",
              "203996     0.0        NaN      798.96  \n",
              "203997     NaN        NaN      825.12  \n",
              "203998     NaN        NaN      640.08  \n",
              "203999     NaN        NaN      540.24  \n",
              "\n",
              "[204000 rows x 10 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_day = pd.read_csv('../train.csv')\n",
        "train_day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1f7205ThUKoJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>건물번호</th>\n",
              "      <th>기온(C)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>습도(%)</th>\n",
              "      <th>태양광용량(kW)</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>week</th>\n",
              "      <th>...</th>\n",
              "      <th>type_day_hour_std</th>\n",
              "      <th>type_hour_mean</th>\n",
              "      <th>type_hour_std</th>\n",
              "      <th>holiday</th>\n",
              "      <th>sin_time</th>\n",
              "      <th>cos_time</th>\n",
              "      <th>THI</th>\n",
              "      <th>CDH</th>\n",
              "      <th>7_shifted_전력소비량</th>\n",
              "      <th>전력소비량(kWh)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.889045</td>\n",
              "      <td>3.2</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>886.546805</td>\n",
              "      <td>1616.129012</td>\n",
              "      <td>909.159339</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>48.2249</td>\n",
              "      <td>-38.9</td>\n",
              "      <td>1085.28</td>\n",
              "      <td>1124.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>18.8</td>\n",
              "      <td>1.889045</td>\n",
              "      <td>2.6</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>906.029700</td>\n",
              "      <td>1603.843635</td>\n",
              "      <td>921.827876</td>\n",
              "      <td>0</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>47.8649</td>\n",
              "      <td>-45.1</td>\n",
              "      <td>1047.36</td>\n",
              "      <td>1059.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>18.5</td>\n",
              "      <td>1.889045</td>\n",
              "      <td>2.6</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>900.729730</td>\n",
              "      <td>1575.108376</td>\n",
              "      <td>916.043890</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>47.4096</td>\n",
              "      <td>-51.4</td>\n",
              "      <td>974.88</td>\n",
              "      <td>987.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>18.1</td>\n",
              "      <td>1.889045</td>\n",
              "      <td>2.2</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>900.693834</td>\n",
              "      <td>1553.335094</td>\n",
              "      <td>908.635022</td>\n",
              "      <td>0</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>46.7941</td>\n",
              "      <td>-58.0</td>\n",
              "      <td>953.76</td>\n",
              "      <td>977.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17.2</td>\n",
              "      <td>1.889045</td>\n",
              "      <td>3.2</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>885.287208</td>\n",
              "      <td>1543.278965</td>\n",
              "      <td>900.520543</td>\n",
              "      <td>0</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>45.6064</td>\n",
              "      <td>-64.9</td>\n",
              "      <td>986.40</td>\n",
              "      <td>1009.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187195</th>\n",
              "      <td>100</td>\n",
              "      <td>23.1</td>\n",
              "      <td>2.533115</td>\n",
              "      <td>0.9</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>812.561591</td>\n",
              "      <td>1728.999353</td>\n",
              "      <td>821.346561</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>63.6624</td>\n",
              "      <td>-19.6</td>\n",
              "      <td>1049.52</td>\n",
              "      <td>881.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187196</th>\n",
              "      <td>100</td>\n",
              "      <td>22.4</td>\n",
              "      <td>2.533115</td>\n",
              "      <td>1.3</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>784.696267</td>\n",
              "      <td>1648.600324</td>\n",
              "      <td>786.021787</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>62.4024</td>\n",
              "      <td>-20.2</td>\n",
              "      <td>874.32</td>\n",
              "      <td>798.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187197</th>\n",
              "      <td>100</td>\n",
              "      <td>21.3</td>\n",
              "      <td>2.533115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>754.000774</td>\n",
              "      <td>1506.193235</td>\n",
              "      <td>757.941653</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>64.1976</td>\n",
              "      <td>-22.3</td>\n",
              "      <td>678.24</td>\n",
              "      <td>825.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187198</th>\n",
              "      <td>100</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2.533115</td>\n",
              "      <td>0.3</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>644.114833</td>\n",
              "      <td>1263.618397</td>\n",
              "      <td>643.779849</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>65.0744</td>\n",
              "      <td>-25.1</td>\n",
              "      <td>632.64</td>\n",
              "      <td>640.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187199</th>\n",
              "      <td>100</td>\n",
              "      <td>20.7</td>\n",
              "      <td>2.533115</td>\n",
              "      <td>0.1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>587.613284</td>\n",
              "      <td>1126.737882</td>\n",
              "      <td>602.556649</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "      <td>65.2725</td>\n",
              "      <td>-28.1</td>\n",
              "      <td>552.72</td>\n",
              "      <td>540.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>187200 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        건물번호  기온(C)   강수량(mm)  풍속(m/s)  습도(%)  태양광용량(kW)  hour  day  month  \\\n",
              "0          1   19.0  1.889045      3.2   61.0          0     0    2      6   \n",
              "1          1   18.8  1.889045      2.6   61.0          0     1    2      6   \n",
              "2          1   18.5  1.889045      2.6   62.0          0     2    2      6   \n",
              "3          1   18.1  1.889045      2.2   63.0          0     3    2      6   \n",
              "4          1   17.2  1.889045      3.2   66.0          0     4    2      6   \n",
              "...      ...    ...       ...      ...    ...        ...   ...  ...    ...   \n",
              "187195   100   23.1  2.533115      0.9   86.0          0    19    2      8   \n",
              "187196   100   22.4  2.533115      1.3   86.0          0    20    2      8   \n",
              "187197   100   21.3  2.533115      1.0   92.0          0    21    2      8   \n",
              "187198   100   21.0  2.533115      0.3   94.0          0    22    2      8   \n",
              "187199   100   20.7  2.533115      0.1   95.0          0    23    2      8   \n",
              "\n",
              "        week  ...  type_day_hour_std  type_hour_mean  type_hour_std  holiday  \\\n",
              "0         23  ...         886.546805     1616.129012     909.159339        0   \n",
              "1         23  ...         906.029700     1603.843635     921.827876        0   \n",
              "2         23  ...         900.729730     1575.108376     916.043890        0   \n",
              "3         23  ...         900.693834     1553.335094     908.635022        0   \n",
              "4         23  ...         885.287208     1543.278965     900.520543        0   \n",
              "...      ...  ...                ...             ...            ...      ...   \n",
              "187195    34  ...         812.561591     1728.999353     821.346561        0   \n",
              "187196    34  ...         784.696267     1648.600324     786.021787        0   \n",
              "187197    34  ...         754.000774     1506.193235     757.941653        0   \n",
              "187198    34  ...         644.114833     1263.618397     643.779849        0   \n",
              "187199    34  ...         587.613284     1126.737882     602.556649        0   \n",
              "\n",
              "        sin_time  cos_time      THI   CDH  7_shifted_전력소비량  전력소비량(kWh)  \n",
              "0       0.000000  1.000000  48.2249 -38.9          1085.28     1124.16  \n",
              "1       0.258819  0.965926  47.8649 -45.1          1047.36     1059.36  \n",
              "2       0.500000  0.866025  47.4096 -51.4           974.88      987.36  \n",
              "3       0.707107  0.707107  46.7941 -58.0           953.76      977.76  \n",
              "4       0.866025  0.500000  45.6064 -64.9           986.40     1009.92  \n",
              "...          ...       ...      ...   ...              ...         ...  \n",
              "187195 -0.965926  0.258819  63.6624 -19.6          1049.52      881.04  \n",
              "187196 -0.866025  0.500000  62.4024 -20.2           874.32      798.96  \n",
              "187197 -0.707107  0.707107  64.1976 -22.3           678.24      825.12  \n",
              "187198 -0.500000  0.866025  65.0744 -25.1           632.64      640.08  \n",
              "187199 -0.258819  0.965926  65.2725 -28.1           552.72      540.24  \n",
              "\n",
              "[187200 rows x 26 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('final_train.csv')\n",
        "test = pd.read_csv('final_test.csv')\n",
        "#train_day = pd.read_csv('../train.csv')\n",
        "#test_day = pd.read_csv('../test.csv')\n",
        "#train = pd.read_csv('')\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnNzTfCdUKoN",
        "outputId": "f8c31ee9-df88-42c0-c480-aad89e2cdd91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['건물번호', '기온(C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '태양광용량(kW)', 'hour',\n",
              "       'day', 'month', 'week', 'month_day_mean', 'day_hour_mean',\n",
              "       'day_hour_std', 'hour_mean', 'hour_std', 'type_day_hour_mean',\n",
              "       'type_day_hour_std', 'type_hour_mean', 'type_hour_std', 'holiday',\n",
              "       'sin_time', 'cos_time', 'THI', 'CDH', '7_shifted_전력소비량', '전력소비량(kWh)'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC6ic48kUKoN"
      },
      "source": [
        "## XGB_ALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hO3dRN68UKoN"
      },
      "outputs": [],
      "source": [
        "def weighted_mse(alpha = 1):\n",
        "    def weighted_mse_fixed(label, pred):\n",
        "        residual = (label - pred).astype(\"float\")\n",
        "        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n",
        "        hess = np.where(residual>0, 2*alpha, 2.0)\n",
        "        return grad, hess\n",
        "    return weighted_mse_fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OVoFrinpUKoN"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def objective_xgb(trial: Trial, X_train, y_train, X_val, y_val):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int('n_estimators', 500, 5000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 8, 16),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "        'gamma': trial.suggest_int('gamma', 1, 3),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        #'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        #'alpha': trial.suggest_loguniform('alpha', 1e-3, 100.0),\n",
        "        #'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1, 100.0, log=True),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
        "        'random_state': 724\n",
        "    }\n",
        "\n",
        "    model = XGBRegressor(**params, tree_method='gpu_hist', gpu_id=0, seed=724, verbosity=2)\n",
        "    alpha_value = model.get_params()['alpha']\n",
        "    model.set_params(**{'objective':weighted_mse(alpha_value)})\n",
        "    model.fit(X_train, y_train, verbose = False, eval_set=[(X_val, y_val)], early_stopping_rounds=50)\n",
        "    y_pred = model.predict(X_val)\n",
        "    score = SMAPE(y_val, y_pred)\n",
        "\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x30cF1k3U11d",
        "outputId": "4a73c3b9-6482-4351-88a9-09e78b75be51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-26 20:00:54,478] A new study created in memory with name: no-name-0553c870-62f7-4f99-82c7-6fa363daf42c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "168538 18662 [0] 100 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:01:29,675] Trial 0 finished with value: 6.83630817487441 and parameters: {'n_estimators': 1966, 'max_depth': 12, 'min_child_weight': 245, 'gamma': 3, 'learning_rate': 0.014, 'colsample_bytree': 0.6430613407852359, 'lambda': 0.0778992548994197, 'alpha': 3.870905691174313, 'subsample': 0.6}. Best is trial 0 with value: 6.83630817487441.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:01:54,246] Trial 1 finished with value: 7.407836531983126 and parameters: {'n_estimators': 4417, 'max_depth': 9, 'min_child_weight': 35, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6682633240688904, 'lambda': 0.0031313356419620775, 'alpha': 19.41973774424242, 'subsample': 0.8}. Best is trial 0 with value: 6.83630817487441.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:02:33,306] Trial 2 finished with value: 6.521873810105373 and parameters: {'n_estimators': 3789, 'max_depth': 13, 'min_child_weight': 169, 'gamma': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.9301983968584033, 'lambda': 2.915429418559948, 'alpha': 60.97562713279073, 'subsample': 0.6}. Best is trial 2 with value: 6.521873810105373.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:03:32,714] Trial 3 finished with value: 6.373577133444422 and parameters: {'n_estimators': 778, 'max_depth': 14, 'min_child_weight': 204, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.9969377844481854, 'lambda': 0.0034040879221076395, 'alpha': 69.34172146751361, 'subsample': 0.6}. Best is trial 3 with value: 6.373577133444422.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:04:15,171] Trial 4 finished with value: 6.645573707451197 and parameters: {'n_estimators': 3371, 'max_depth': 16, 'min_child_weight': 250, 'gamma': 1, 'learning_rate': 0.014, 'colsample_bytree': 0.6663245230242629, 'lambda': 9.351622655115788, 'alpha': 5.124443766013099, 'subsample': 0.7}. Best is trial 3 with value: 6.373577133444422.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:11:15,019] Trial 5 finished with value: 5.3472138900014805 and parameters: {'n_estimators': 3674, 'max_depth': 15, 'min_child_weight': 74, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.5419202648309227, 'lambda': 6.3499049788790165, 'alpha': 8.808688504435565, 'subsample': 0.8}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:12:41,628] Trial 6 finished with value: 6.1913776962906 and parameters: {'n_estimators': 4873, 'max_depth': 15, 'min_child_weight': 77, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.5421008673330383, 'lambda': 1.2334021759642408, 'alpha': 19.288611773067018, 'subsample': 1.0}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:13:04,894] Trial 7 finished with value: 7.552409288928865 and parameters: {'n_estimators': 4939, 'max_depth': 8, 'min_child_weight': 203, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.6674209463504781, 'lambda': 0.3544313216632215, 'alpha': 7.388773646529587, 'subsample': 1.0}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:13:35,768] Trial 8 finished with value: 7.090058430435355 and parameters: {'n_estimators': 1122, 'max_depth': 10, 'min_child_weight': 201, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.667779924393187, 'lambda': 0.23319270089423416, 'alpha': 6.5550147011825, 'subsample': 0.8}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:14:17,255] Trial 9 finished with value: 7.1071544181723425 and parameters: {'n_estimators': 3972, 'max_depth': 10, 'min_child_weight': 145, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.7428944807001934, 'lambda': 0.0014041165083543466, 'alpha': 14.151026517567383, 'subsample': 1.0}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:19:21,425] Trial 10 finished with value: 5.361213692990141 and parameters: {'n_estimators': 2715, 'max_depth': 16, 'min_child_weight': 98, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.509291407799836, 'lambda': 8.215402965029998, 'alpha': 1.416295220063767, 'subsample': 0.8}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:24:35,789] Trial 11 finished with value: 5.436180175358885 and parameters: {'n_estimators': 2694, 'max_depth': 16, 'min_child_weight': 103, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.5008115616484576, 'lambda': 7.9631362782704045, 'alpha': 1.0161925041983768, 'subsample': 0.8}. Best is trial 5 with value: 5.3472138900014805.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:29:48,370] Trial 12 finished with value: 5.187187257650038 and parameters: {'n_estimators': 2527, 'max_depth': 14, 'min_child_weight': 20, 'gamma': 2, 'learning_rate': 0.01, 'colsample_bytree': 0.5566789844218, 'lambda': 1.5843466654938696, 'alpha': 1.8561694361578585, 'subsample': 0.8}. Best is trial 12 with value: 5.187187257650038.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:34:38,364] Trial 13 finished with value: 5.260189788167301 and parameters: {'n_estimators': 1983, 'max_depth': 13, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.01, 'colsample_bytree': 0.5733032397920131, 'lambda': 1.5167420275594123, 'alpha': 2.1371160716254285, 'subsample': 0.8}. Best is trial 12 with value: 5.187187257650038.\n",
            "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-26 20:37:59,134] Trial 14 finished with value: 5.3530693736278545 and parameters: {'n_estimators': 1774, 'max_depth': 12, 'min_child_weight': 9, 'gamma': 2, 'learning_rate': 0.01, 'colsample_bytree': 0.5736735598774076, 'lambda': 1.1310790985255565, 'alpha': 2.316828807281041, 'subsample': 0.7}. Best is trial 12 with value: 5.187187257650038.\n"
          ]
        }
      ],
      "source": [
        "# 0\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_0.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([0])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([0])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "\n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "    print(len(x_train), len(x_val), x_val['day'].unique(), x_val['건물번호'].nunique(), x_val['hour'].nunique())\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_0 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6xjPFfqV_NJ",
        "outputId": "e63981ef-ace5-4b2e-8dee-c0f9f4703086"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-25 01:23:19,674] A new study created in memory with name: no-name-fe0a278d-9ae6-4ee0-8c97-459655329667\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-25 01:28:34,440] Trial 0 finished with value: 4.255823374085603 and parameters: {'n_estimators': 2736, 'max_depth': 8, 'min_child_weight': 39, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.8179836403047569, 'lambda': 2.6942762098193436, 'alpha': 2.9136439818095887, 'subsample': 0.8}. Best is trial 0 with value: 4.255823374085603.\n",
            "[I 2023-08-25 01:38:15,107] Trial 1 finished with value: 3.638964764141043 and parameters: {'n_estimators': 4666, 'max_depth': 11, 'min_child_weight': 82, 'gamma': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.7054693692062667, 'lambda': 0.0150191590603315, 'alpha': 1.3669666557932334, 'subsample': 1.0}. Best is trial 1 with value: 3.638964764141043.\n",
            "[I 2023-08-25 01:48:02,383] Trial 2 finished with value: 3.5595839551786206 and parameters: {'n_estimators': 4026, 'max_depth': 14, 'min_child_weight': 96, 'gamma': 2, 'learning_rate': 0.018, 'colsample_bytree': 0.8915812809633243, 'lambda': 0.0698568656347382, 'alpha': 4.7113709647853375, 'subsample': 0.8}. Best is trial 2 with value: 3.5595839551786206.\n",
            "[I 2023-08-25 01:51:42,955] Trial 3 finished with value: 3.9018987141950734 and parameters: {'n_estimators': 1464, 'max_depth': 16, 'min_child_weight': 167, 'gamma': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.6848496745328279, 'lambda': 2.5670955636618915, 'alpha': 3.5571934398106984, 'subsample': 1.0}. Best is trial 2 with value: 3.5595839551786206.\n",
            "[I 2023-08-25 01:52:50,748] Trial 4 finished with value: 5.021799635513283 and parameters: {'n_estimators': 4019, 'max_depth': 12, 'min_child_weight': 194, 'gamma': 3, 'learning_rate': 0.012, 'colsample_bytree': 0.7815850918213384, 'lambda': 0.0031944292691682852, 'alpha': 26.067378061764806, 'subsample': 1.0}. Best is trial 2 with value: 3.5595839551786206.\n",
            "[I 2023-08-25 01:57:52,662] Trial 5 finished with value: 3.519449725199707 and parameters: {'n_estimators': 2073, 'max_depth': 16, 'min_child_weight': 47, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.8075165688829582, 'lambda': 0.002008901112357816, 'alpha': 1.075158924630285, 'subsample': 1.0}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:06:01,716] Trial 6 finished with value: 4.042037563624143 and parameters: {'n_estimators': 4380, 'max_depth': 11, 'min_child_weight': 282, 'gamma': 2, 'learning_rate': 0.01, 'colsample_bytree': 0.6871011083456268, 'lambda': 0.002207970364394128, 'alpha': 1.0961940893485718, 'subsample': 0.6}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:08:49,980] Trial 7 finished with value: 3.9668939901629985 and parameters: {'n_estimators': 797, 'max_depth': 16, 'min_child_weight': 73, 'gamma': 3, 'learning_rate': 0.014, 'colsample_bytree': 0.673041573533544, 'lambda': 0.001012525962453544, 'alpha': 54.872407519176136, 'subsample': 1.0}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:12:26,827] Trial 8 finished with value: 4.100141028789791 and parameters: {'n_estimators': 2170, 'max_depth': 16, 'min_child_weight': 220, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.621468951833551, 'lambda': 0.32832968124475376, 'alpha': 60.93533867143597, 'subsample': 0.7}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:15:39,280] Trial 9 finished with value: 4.403131723989285 and parameters: {'n_estimators': 1793, 'max_depth': 8, 'min_child_weight': 263, 'gamma': 2, 'learning_rate': 0.016, 'colsample_bytree': 0.9109649011251434, 'lambda': 0.553331849382302, 'alpha': 2.608991809412947, 'subsample': 1.0}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:25:14,086] Trial 10 finished with value: 3.537607675343963 and parameters: {'n_estimators': 3167, 'max_depth': 14, 'min_child_weight': 9, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.5454381857678074, 'lambda': 0.013644315836595722, 'alpha': 10.442476275361722, 'subsample': 0.7}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:34:52,583] Trial 11 finished with value: 3.53545413419084 and parameters: {'n_estimators': 3152, 'max_depth': 14, 'min_child_weight': 9, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.5552333726424398, 'lambda': 0.009939054856874137, 'alpha': 11.23902916887389, 'subsample': 0.7}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:44:24,972] Trial 12 finished with value: 3.564520783110683 and parameters: {'n_estimators': 3055, 'max_depth': 14, 'min_child_weight': 7, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.5083733087589292, 'lambda': 0.008664226189876525, 'alpha': 9.82139073265561, 'subsample': 0.7}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:45:17,602] Trial 13 finished with value: 4.217529050836242 and parameters: {'n_estimators': 2527, 'max_depth': 14, 'min_child_weight': 126, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.9822583357984604, 'lambda': 0.040755925899376315, 'alpha': 9.169290316799378, 'subsample': 0.6}. Best is trial 5 with value: 3.519449725199707.\n",
            "[I 2023-08-25 02:52:16,533] Trial 14 finished with value: 3.5030045723010517 and parameters: {'n_estimators': 3601, 'max_depth': 15, 'min_child_weight': 41, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.6166898175221656, 'lambda': 0.005020788329821443, 'alpha': 1.0083283596159296, 'subsample': 0.7}. Best is trial 14 with value: 3.5030045723010517.\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_1.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([1])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([1])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "    \n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_1 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJxYmkurWuJG",
        "outputId": "74435fd6-2b93-4045-fce8-4ab3bbbb5d89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-25 03:00:49,975] A new study created in memory with name: no-name-c359f472-a793-4ff3-a930-9d71811aeacd\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2023-08-25 03:11:46,633] Trial 0 finished with value: 4.0490465693869595 and parameters: {'n_estimators': 4831, 'max_depth': 15, 'min_child_weight': 123, 'gamma': 3, 'learning_rate': 0.014, 'colsample_bytree': 0.6321523185080865, 'lambda': 5.360325927671868, 'alpha': 1.6902914053128546, 'subsample': 0.6}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:16:57,593] Trial 1 finished with value: 4.488178022066473 and parameters: {'n_estimators': 1125, 'max_depth': 16, 'min_child_weight': 47, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.5435158204677171, 'lambda': 0.008930380038361723, 'alpha': 44.992316929263765, 'subsample': 0.7}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:25:08,170] Trial 2 finished with value: 4.6110631565104265 and parameters: {'n_estimators': 4528, 'max_depth': 9, 'min_child_weight': 242, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.9871289329773583, 'lambda': 2.1404959211152157, 'alpha': 3.840244144759925, 'subsample': 0.7}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:27:30,048] Trial 3 finished with value: 4.929155301589333 and parameters: {'n_estimators': 1207, 'max_depth': 10, 'min_child_weight': 300, 'gamma': 1, 'learning_rate': 0.01, 'colsample_bytree': 0.6108816599038667, 'lambda': 0.035614405660781966, 'alpha': 1.0572389836189175, 'subsample': 1.0}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:28:24,148] Trial 4 finished with value: 6.527496977147794 and parameters: {'n_estimators': 3107, 'max_depth': 10, 'min_child_weight': 254, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.5914034052030629, 'lambda': 0.09530454563573766, 'alpha': 9.025017033771247, 'subsample': 1.0}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:37:52,561] Trial 5 finished with value: 4.146075858750146 and parameters: {'n_estimators': 4095, 'max_depth': 16, 'min_child_weight': 117, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.6226419295664166, 'lambda': 6.670319017437426, 'alpha': 2.2453122583092084, 'subsample': 0.6}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:38:28,138] Trial 6 finished with value: 7.641359285537009 and parameters: {'n_estimators': 4070, 'max_depth': 8, 'min_child_weight': 288, 'gamma': 3, 'learning_rate': 0.016, 'colsample_bytree': 0.781341667437532, 'lambda': 0.002046380488875386, 'alpha': 43.58753772815516, 'subsample': 0.6}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:39:08,239] Trial 7 finished with value: 6.731931689766682 and parameters: {'n_estimators': 1704, 'max_depth': 9, 'min_child_weight': 112, 'gamma': 1, 'learning_rate': 0.014, 'colsample_bytree': 0.8558498568628721, 'lambda': 0.053059918234145305, 'alpha': 53.38922851049679, 'subsample': 1.0}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:40:04,209] Trial 8 finished with value: 7.732689112940365 and parameters: {'n_estimators': 1057, 'max_depth': 9, 'min_child_weight': 15, 'gamma': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.5693188527183571, 'lambda': 1.9362511835495773, 'alpha': 22.29432223874854, 'subsample': 1.0}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:46:16,567] Trial 9 finished with value: 4.762029563125831 and parameters: {'n_estimators': 3573, 'max_depth': 8, 'min_child_weight': 288, 'gamma': 1, 'learning_rate': 0.014, 'colsample_bytree': 0.5306142935633472, 'lambda': 0.4813829046141198, 'alpha': 1.7130371816179344, 'subsample': 0.8}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 03:51:26,910] Trial 10 finished with value: 4.4211740390971395 and parameters: {'n_estimators': 2321, 'max_depth': 14, 'min_child_weight': 187, 'gamma': 2, 'learning_rate': 0.018, 'colsample_bytree': 0.6948442226403466, 'lambda': 8.950159335140226, 'alpha': 5.304963059079342, 'subsample': 0.6}. Best is trial 0 with value: 4.0490465693869595.\n",
            "[I 2023-08-25 04:02:46,917] Trial 11 finished with value: 4.094100493970913 and parameters: {'n_estimators': 4798, 'max_depth': 16, 'min_child_weight': 116, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.6658575497191717, 'lambda': 8.187991728446573, 'alpha': 2.2062129105395156, 'subsample': 0.6}. Best is trial 0 with value: 4.0490465693869595.\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_2.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([2])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([2])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "\n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_2 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32tPKn6dWyuf"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_3.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([3])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([3])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "\n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_3 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0hBL9QfW3Y0"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_4.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([4])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([4])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "\n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_4 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bbq4XYZW61M"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_5.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([5])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([5])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "\n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_5 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tdL9kCJW-Ce"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "preds = np.array([])\n",
        "best_params = {}\n",
        "best_values = {}  # New dictionary to store the best values\n",
        "with open('best_params_values_0825_6.txt', 'w') as f:\n",
        "    # Select the data for the current num\n",
        "    num_data = train.copy()\n",
        "\n",
        "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
        "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
        "    num_data['stratified_target'] = num_data['건물번호'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['hour'].astype(str)\n",
        "\n",
        "    # Split the data into training and validation set\n",
        "    train_df, val_df = train_test_split(num_data, test_size=0.7, stratify=num_data['stratified_target'], random_state=724)\n",
        "\n",
        "    # Drop the temporary feature\n",
        "    train_df = train_df.drop(columns='stratified_target')\n",
        "    val_df = val_df.drop(columns='stratified_target')\n",
        "\n",
        "    # Validation set에서 day 값이 0이 아닌 행을 training set에 추가\n",
        "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([6])]])\n",
        "\n",
        "    # Validation set에서 day 값이 0인 행만 남기기\n",
        "    val_df = val_df[val_df['day'].isin([6])]\n",
        "\n",
        "    y_train = train_df['전력소비량(kWh)']\n",
        "    y_val = val_df['전력소비량(kWh)']\n",
        "\n",
        "    x_train, x_test = train_df.copy(), test.copy()\n",
        "    x_val = val_df.copy()\n",
        "\n",
        "    x_train.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "    x_val.drop(['전력소비량(kWh)'],axis=1,inplace=True)\n",
        "\n",
        "    x_test = x_test[x_train.columns]\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=15)\n",
        "    param = study.best_trial.params\n",
        "    best_params = param\n",
        "    best_values = study.best_trial.value  # Store the best value\n",
        "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
        "    f.flush()\n",
        "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
        "    alpha_value2 = xgb.get_params()['alpha']\n",
        "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
        "    xgb.fit(x_train, y_train)\n",
        "    y_pred = xgb.predict(x_test)\n",
        "    pred_6 = np.append(preds, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRusaxKwXEoE"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/electric/sample_submission.csv')\n",
        "submission['answer_0'] = pred_0\n",
        "submission['answer_1'] = pred_1\n",
        "submission['answer_2'] = pred_2\n",
        "submission['answer_3'] = pred_3\n",
        "submission['answer_4'] = pred_4\n",
        "submission['answer_5'] = pred_5\n",
        "submission['answer_6'] = pred_6\n",
        "\n",
        "# 'num_date_time'에서 년월일 부분만 추출\n",
        "submission['date'] = submission['num_date_time'].apply(lambda x: x.split('_')[1])\n",
        "submission['date'] = submission['date'].apply(lambda x: x.split(' ')[0])\n",
        "\n",
        "# 먼저 'answer' 컬럼을 'answer_34'와 'answer_5'의 평균으로 초기화\n",
        "submission['answer'] = (submission['answer_0'] + submission['answer_1'] + submission['answer_2'] + submission['answer_3'] + submission['answer_4'] + submission['answer_5'] + submission['answer_6']) / 7\n",
        "\n",
        "print(submission)\n",
        "# 'date'가 '20220826' 또는 '20220827'인 행의 'answer' 값을 해당 날짜의 'answer_34' 값으로 변경\n",
        "submission.loc[submission['date'].isin(['20220825', '20220826']), 'answer'] = submission.loc[submission['date'].isin(['20220825', '20220826']), 'answer_34']\n",
        "\n",
        "# 'date'가 '20220828'인 행의 'answer' 값을 해당 날짜의 'answer_5' 값으로 변경\n",
        "\n",
        "submission.loc[submission['date'] == '20220825', 'answer'] = submission.loc[submission['date'] == '20220825', 'answer_3']\n",
        "submission.loc[submission['date'] == '20220826', 'answer'] = submission.loc[submission['date'] == '20220826', 'answer_4']\n",
        "submission.loc[submission['date'] == '20220827', 'answer'] = submission.loc[submission['date'] == '20220827', 'answer_5']\n",
        "submission.loc[submission['date'] == '20220828', 'answer'] = submission.loc[submission['date'] == '20220828', 'answer_6']\n",
        "submission.loc[submission['date'] == '20220829', 'answer'] = submission.loc[submission['date'] == '20220829', 'answer_0']\n",
        "submission.loc[submission['date'] == '20220830', 'answer'] = submission.loc[submission['date'] == '20220830', 'answer_1']\n",
        "submission.loc[submission['date'] == '20220831', 'answer'] = submission.loc[submission['date'] == '20220831', 'answer_2']\n",
        "\n",
        "# 불필요한 컬럼 삭제\n",
        "submission = submission.drop(columns=['date', 'answer_0', 'answer_1', 'answer_2', 'answer_3', 'answer_4', 'answer_5','answer_6'])\n",
        "\n",
        "submission.to_csv('7day_optuna_iter15_seed724.csv', index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLuH3UoiUKoO"
      },
      "source": [
        "# ens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etcj0wjUKoO"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
